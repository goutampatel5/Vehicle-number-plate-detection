{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18b507f-6bc5-4ba9-bc55-c32fa4692c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 25470 images, 25470 labels\n",
      "Test set: 386 images, 386 labels\n",
      "Val set: 1073 images, 1073 labels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"/home/shivamp22co/ml_project/dataset\"\n",
    "for split in [\"train\", \"test\", \"val\"]:\n",
    "    images_dir = os.path.join(dataset_path, \"images\", split)\n",
    "\n",
    "    labels_dir = os.path.join(dataset_path, \"labels\", split)\n",
    "    print(f\"{split.capitalize()} set: {len(os.listdir(images_dir))} images, {len(os.listdir(labels_dir))} labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a252f61-1e87-4198-9f18-91ade78f7422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import Image\n",
    "\n",
    "# Check if GPU is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Path to YOLOv7 directory\n",
    "yolov7_path = \"yolov7\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f057d35-509f-4c4c-bda9-eabddef0dad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 14:45:45.228882: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-24 14:45:45.246981: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-24 14:45:45.265941: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-24 14:45:45.271310: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-24 14:45:45.285659: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-24 14:45:46.518166: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beceb485-b86c-474c-9565-b2ab80a2ddaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fce3caa3-f630-4f3a-80db-4fd72363b1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-20 18:05:17.314464: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-20 18:05:17.325744: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-20 18:05:17.338278: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-20 18:05:17.341979: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-20 18:05:17.351229: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-20 18:05:17.951291: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "YOLOR ðŸš€ 2024-10-20 torch 2.5.0+cu124 CPU\n",
      "\n",
      "Namespace(weights='yolov7.pt', cfg='', data='dataset.yaml', hyp='./yolov7/data/hyp.scratch.p5.yaml', epochs=50, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='cpu', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='exp', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/exp', total_batch_size=16)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
      "/home/shivamp22co/ml_project/yolov7/train.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  run_id = torch.load(weights, map_location=device).get('wandb_id') if weights.endswith('.pt') and os.path.isfile(weights) else None\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
      "/home/shivamp22co/ml_project/yolov7/train.py:87: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(weights, map_location=device)  # load checkpoint\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 12                -1  1         0  models.common.MP                        []                            \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
      " 25                -1  1         0  models.common.MP                        []                            \n",
      " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 38                -1  1         0  models.common.MP                        []                            \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 76                -1  1         0  models.common.MP                        []                            \n",
      " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
      " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 89                -1  1         0  models.common.MP                        []                            \n",
      " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
      " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
      " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "105   [102, 103, 104]  1     32310  models.yolo.Detect                      [1, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
      "Model Summary: 407 layers, 37194710 parameters, 37194710 gradients\n",
      "\n",
      "Transferred 554/560 items from yolov7.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 95 .bias, 95 conv.weight, 92 other\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/shivamp22co/ml_project/dataset/labels/train' images and l\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/shivamp22co/ml_project/dataset/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/shivamp22co/ml_project/dataset/labels/val' images and label\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/shivamp22co/ml_project/dataset/labels/val.cache\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.78, Best Possible Recall (BPR) = 0.9933\n",
      "/home/shivamp22co/ml_project/yolov7/train.py:299: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=cuda)\n",
      "Image sizes 640 train, 640 test\n",
      "Using 8 dataloader workers\n",
      "Logging results to runs/train/exp\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "  0%|                                                  | 0/1592 [00:00<?, ?it/s]/home/shivamp22co/ml_project/yolov7/train.py:360: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(enabled=cuda):\n",
      "      0/49        0G   0.08732   0.01629         0    0.1036        31       640^C\n"
     ]
    }
   ],
   "source": [
    "!python yolov7/train.py --img 640 --batch 16 --epochs 50 --data dataset.yaml --weights yolov7.pt --device 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c7266-3e4c-4934-8df4-228d1eb33818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorBoard if not installed\n",
    "!pip install tensorboard\n",
    "\n",
    "# Run TensorBoard to monitor training progress\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d78130-40aa-4230-b120-1970bc1fc647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-24 14:26:23.890980: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-24 14:26:23.912281: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-24 14:26:23.940736: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-24 14:26:23.947995: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-24 14:26:23.970781: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-24 14:26:25.266864: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "YOLOR ðŸš€ 2024-10-20 torch 2.5.0+cu124 CPU\n",
      "\n",
      "Namespace(weights='yolov7.pt', cfg='yolov7/cfg/training/yolov7.yaml', data='dataset.yaml', hyp='./yolov7/data/hyp.scratch.p5.yaml', epochs=300, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='cpu', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='exp', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/exp', total_batch_size=16)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
      "/home/shivamp22co/ml_project/yolov7/train.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  run_id = torch.load(weights, map_location=device).get('wandb_id') if weights.endswith('.pt') and os.path.isfile(weights) else None\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
      "/home/shivamp22co/ml_project/yolov7/train.py:87: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(weights, map_location=device)  # load checkpoint\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 12                -1  1         0  models.common.MP                        []                            \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
      " 25                -1  1         0  models.common.MP                        []                            \n",
      " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 38                -1  1         0  models.common.MP                        []                            \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 76                -1  1         0  models.common.MP                        []                            \n",
      " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
      " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 89                -1  1         0  models.common.MP                        []                            \n",
      " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
      " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
      " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "105   [102, 103, 104]  1     34156  models.yolo.IDetect                     [1, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
      "Model Summary: 415 layers, 37196556 parameters, 37196556 gradients\n",
      "\n",
      "Transferred 552/566 items from yolov7.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/shivamp22co/ml_project/dataset/labels/train' images and l\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/shivamp22co/ml_project/dataset/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/shivamp22co/ml_project/dataset/labels/val' images and label\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/shivamp22co/ml_project/dataset/labels/val.cache\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.78, Best Possible Recall (BPR) = 0.9933\n",
      "/home/shivamp22co/ml_project/yolov7/train.py:299: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=cuda)\n",
      "Image sizes 640 train, 640 test\n",
      "Using 8 dataloader workers\n",
      "Logging results to runs/train/exp\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "  0%|                                                  | 0/1592 [00:00<?, ?it/s]/home/shivamp22co/ml_project/yolov7/train.py:360: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(enabled=cuda):\n",
      "^C\n",
      "  0%|                                                  | 0/1592 [00:09<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shivamp22co/ml_project/yolov7/train.py\", line 616, in <module>\n",
      "    train(hyp, opt, device, tb_writer)\n",
      "  File \"/home/shivamp22co/ml_project/yolov7/train.py\", line 361, in train\n",
      "    pred = model(imgs)  # forward\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/shivamp22co/.local/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shivamp22co/.local/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shivamp22co/ml_project/yolov7/models/yolo.py\", line 599, in forward\n",
      "    return self.forward_once(x, profile)  # single-scale inference, train\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shivamp22co/ml_project/yolov7/models/yolo.py\", line 625, in forward_once\n",
      "    x = m(x)  # run\n",
      "        ^^^^\n",
      "  File \"/home/shivamp22co/.local/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shivamp22co/.local/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shivamp22co/ml_project/yolov7/models/common.py\", line 108, in forward\n",
      "    return self.act(self.bn(self.conv(x)))\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shivamp22co/.local/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shivamp22co/.local/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shivamp22co/.local/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/shivamp22co/.local/lib/python3.12/site-packages/torch/nn/functional.py\", line 2812, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python yolov7/train.py --data dataset.yaml --weights yolov7.pt --batch-size 16 --img 640 640 --cfg yolov7/cfg/training/yolov7.yaml --device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf50a9-9804-4ce5-90f9-186bc3d61a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on a test image using the trained model\n",
    "!python yolov7/inference.py --weights yolov7/runs/train/exp/weights/best.pt --source dataset/images/test --img 640 --conf 0.25 --device 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a121972-3f2e-4d48-8d72-fdcbfa20fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on the test set\n",
    "!python yolov7/test.py --weights yolov7/runs/train/exp/weights/best.pt --data dataset.yaml --img 640 --device 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
